# AI Resume Compatibility Analyzer

A powerful, microservices-based application that leverages local Large Language Models (LLMs) to analyze resumes against job descriptions. It uses **Ollama** for generative AI analysis and **OCR** for robust text extraction from PDFs and images.

## üöÄ Features

- **Generative AI Analysis**: Uses locally hosted LLMs (via Ollama, default: `qwen2.5:7b`) to provide detailed feedback, matching scores, and recommendations.
- **Robust OCR**: Extracts text from both image-based and text-based PDFs using Tesseract and PyMuPDF.
- **Microservices Architecture**: Decoupled services communicating efficiently via **Apache Kafka**.
- **Modern UI**: React-based dashboard for easy uploading and result visualization.
- **Secure**: User authentication and secure file storage with **MinIO**.

## üèó Architecture

The system consists of the following Dockerized services:

1.  **Frontend (`app-frontend`)**: React application served via Nginx.
2.  **Backend (`app-backend`)**: Spring Boot application handling API requests, file management, and coordination.
3.  **NLP Service (`nlp-service`)**: Python service consuming Kafka messages, performing OCR, and interacting with Ollama.
4.  **Ollama (`ollama`)**: Runs the local LLM inference server.
5.  **Kafka & Zookeeper**: Message broker for asynchronous communication between Backend and NLP Service.
6.  **MinIO**: Object storage for resumes.
7.  **PostgreSQL**: Relational database for user data and analysis history.

## üõ† Prerequisites

- **Docker** and **Docker Compose** installed.
- **RAM**: At least 8GB (16GB recommended) available for running the LLM and containers.
- **Disk Space**: ~10GB free space (for Docker images and the ~4.7GB LLM model).

## üèÅ Getting Started

### 1. Clone the Repository
```bash
git clone <repository-url>
cd AI_Analyser
```

### 2. Build and Start Services
Run the following command to build and start all services:

```bash
docker-compose up -d --build
```

### 3. Model Download (First Run Only)
On the very first startup, the `ollama` service needs to download the AI model (`qwen2.5:7b`, approx 4.7GB). 

**IMPORTANT**: The analysis features will NOT work until this download completes.

You can check the progress by viewing the Ollama logs:
```bash
docker logs -f resume_ollama
```
Wait until you see a message indicating the download is complete or the server is listening.

### 4. Access the Application
- **Frontend**: [http://localhost:3000](http://localhost:3000) (or port 80 depending on configuration, check `docker ps`)
- **Backend API**: [http://localhost:8080](http://localhost:8080)
- **MinIO Console**: [http://localhost:9001](http://localhost:9001) (User/Pass: `minioadmin` / `minioadmin`)

## üìñ Usage

1.  **Register/Login**: Create an account on the frontend.
2.  **Analyze**:
    - Upload a Resume (PDF, JPG, PNG).
    - Paste the Job Description.
    - Click **Analyze**.
3.  **View Results**:
    - **Compatibility Score**: A 0-100 score indicating fit.
    - **Key Strengths**: Skills found in your resume that match the job.
    - **Missing Skills**: Critical gaps identified.
    - **Recommendation**: Personalized advice generated by the AI.

## üîß Troubleshooting

- **Analysis Timeout**: If the first analysis hangs, it's likely because the model is still downloading. Check `docker logs resume_ollama` and wait.
- **Kafka Connection Errors**: Services might restart if Kafka isn't ready. Docker Compose handles retries, but you can manually restart a service:
  ```bash
  docker-compose restart app-backend
  ```

## üì¶ Tech Stack

- **Java 21 (Spring Boot 3)**
- **Python 3.9 (Spacy, Tesseract, PyMuPDF)**
- **React (Vite, Tailwind CSS)**
- **Apache Kafka**
- **PostgreSQL**
- **MinIO**
- **Ollama**
